{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae5fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "os.environ[\"TORCH_USE_CUDA_DSA\"] = \"1\"\n",
    "\n",
    "import torch\n",
    "\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2c5645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from natsort import natsorted\n",
    "from lib.utils.promptLoader import PromptLoader\n",
    "\n",
    "prompt = PromptLoader(\"resources/prompts/lightfootcat_prompt.yaml\")\n",
    "image_path = \"resources/images/lightfootcat/images/cropped\"\n",
    "images = natsorted([os.path.join(image_path, i) for i in os.listdir(image_path)])\n",
    "sample_images = images[:5]#np.random.choice(images, 5)\n",
    "\n",
    "def plot_images(images):\n",
    "    fig, ax = plt.subplots(1, 5, figsize=(20, 5))\n",
    "    for i, image in enumerate(images):\n",
    "        img = cv2.imread(image) if isinstance(image, str) else image\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax[i].imshow(img)\n",
    "        ax[i].axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5dac01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_images(sample_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac81da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.model.ocr_model import OCRModel\n",
    "\n",
    "ocr = OCRModel(prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638e3ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_outs_without_preprocessing = [ocr([image]) for image in sample_images]\n",
    "\n",
    "for i, image in enumerate(sample_images):\n",
    "    img = cv2.imread(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Image {i+1}\")\n",
    "    plt.show()\n",
    "    print(f\"Image {i+1} OCR Output:\")\n",
    "    print(sample_outs_without_preprocessing[i])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c5054",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocessing the images\n",
    "\n",
    "print(\"Initial Images\")\n",
    "plot_images(sample_images)\n",
    "\n",
    "print(\"Step 1: Grayscale Conversion\")\n",
    "gray_images = [cv2.cvtColor(cv2.imread(image), cv2.COLOR_BGR2GRAY) for image in sample_images]\n",
    "plot_images(gray_images)\n",
    "\n",
    "print(\"Step 2: Remove shadows\")\n",
    "thresh = lambda x: cv2.adaptiveThreshold(x, 255,\n",
    "                               cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                               cv2.THRESH_BINARY, 31, 10)\n",
    "\n",
    "median_filter = lambda x: cv2.medianBlur(x, 3)\n",
    "shadows_removes = [median_filter(thresh(image)) for image in gray_images]\n",
    "plot_images(shadows_removes)\n",
    "\n",
    "\n",
    "print(\"Step 3: Noise Reductiion\")\n",
    "denoised_images = [cv2.bilateralFilter(image, 9, 75, 75) for image in shadows_removes]\n",
    "plot_images(denoised_images)\n",
    "\n",
    "print(\"Setp 4: Binarization (black and White) via Otsu's method\")\n",
    "binarized_images = [cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)[1] for image in denoised_images]\n",
    "plot_images(binarized_images)\n",
    "\n",
    "print(\"Step 5: Deskewing\")\n",
    "print(\"Skipping deskewing for now\")\n",
    "deskewed_images = binarized_images\n",
    "#deskewed_images = [deskew(image) for image in binarized_images]\n",
    "#plot_images(deskewed_images)\n",
    "\n",
    "print(\"Step 6: Morphological opening (erosion followed by dilation)\")\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1,1))#np.ones((1, 1), np.uint8)\n",
    "opened = lambda x: cv2.morphologyEx(x, cv2.MORPH_OPEN,\n",
    "                                    kernel, iterations=1)\n",
    "opened_images = [opened(image) for image in deskewed_images]\n",
    "plot_images(opened_images)\n",
    "\n",
    "print(\"Step 7: Optional dilation to thicken strokes\")\n",
    "kernel2 = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
    "processed = [cv2.dilate(i, kernel2, iterations=1) for i in opened_images]\n",
    "plot_images(processed)\n",
    "\n",
    "temp_dir = \"temp/\"\n",
    "processod_images = []\n",
    "for ind, i in enumerate(processed):\n",
    "    fname = os.path.join(temp_dir, str(ind) + \".png\")\n",
    "    cv2.imwrite(fname, i)\n",
    "    processod_images.append(fname)\n",
    "    print(fname)\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0a4981",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_outs_with_preprocessing = [ocr.extract_text([image], clean=False) for image in processed]\n",
    "\n",
    "for i, image in enumerate(processed):\n",
    "    #img = cv2.imread(image)\n",
    "    img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"Image {i+1}\")\n",
    "    plt.show()\n",
    "    print(f\"Image {i+1} OCR Output:\")\n",
    "    print(sample_outs_with_preprocessing[i])\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df9abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index = 2\n",
    "print(sample_outs_with_preprocessing[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2dc3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "\n",
    "    text = text.strip()\n",
    "    # Clean line breaks\n",
    "    text = re.sub(r\"-\\n+\", \"\", text)\n",
    "    text = re.sub(r\"^(\\d*|[a-z]{0,3})\\s?(Joh|Cat).*\\n\", \"\", text, re.I)\n",
    "    text = re.sub(r\"^.*(l?o?gue|ghtfoot|foot)\\s?(\\d*)?\\n\", \"\", text, re.I)\n",
    "    text = re.sub(r\"([a-zA-Z])-\\n([a-zA-Z])\", r\"\\1\\2\", text)\n",
    "    text = re.sub(r\"([A-Z]+)\\s*(EAE|FAE|EAF)\", r\"\\1EAE\", text)\n",
    "\n",
    "    # Add a newline before any indexing patterns like 1. or i. or a., but only if not part of a word ending\n",
    "    # Ensure the pattern is preceded by whitespace or start of line, and not a letter (to avoid word endings)\n",
    "    # exclusions = r'(?:e\\.g\\.|i\\.e\\.|etc\\.|cf\\.|vs\\.)'\n",
    "    # text = re.sub(rf'(?<![a-zA-Z0-9])\\s+(?!{exclusions})(\\d+\\.)\\n?', r'\\n\\1', text)\n",
    "    # text = re.sub(rf'(?<![a-zA-Z0-9])\\s+(?!{exclusions})([ivxlc]+\\.)\\n?', r'\\n\\1', text)\n",
    "    # text = re.sub(rf'(?<![a-zA-Z0-9])\\s+(?!{exclusions})([a-z]\\.)\\n?', r'\\n\\1', text)\n",
    "\n",
    "    text = re.sub(r\"\\n\\n+\", \"\\n\\n\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def full_clean_text(text_list: list[str]) -> list[str]:\n",
    "\n",
    "    cleaned_texts = []\n",
    "\n",
    "    for i, text in enumerate(text_list):\n",
    "        text = text if isinstance(text, list) else [text]\n",
    "\n",
    "        cleaned = [clean_text(t) for t in text if not(re.match(r\"^\\n*$\", t))]\n",
    "\n",
    "        cleaned_texts.append(\"\".join(cleaned))\n",
    "\n",
    "    return cleaned_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375e87de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# sample = sample_outs_with_preprocessing[index]\n",
    "# sample = sample.split(\"\\n\\n\\n\\n\\n\")\n",
    "# out = \" \".join(full_clean_text(sample))\n",
    "# print(\"Sample OCR Output:\")\n",
    "# print(sample)\n",
    "# print(\"Cleaned OCR Output:\")\n",
    "# print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_n = lambda x: re.sub(r\"\\n\\n\\n\\n\\n\", \"\\n\\n\", x)\n",
    "sample_outs_with_preprocessing = [clean_text(clean_n(i)) for i in sample_outs_with_preprocessing]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654110c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\".join(sample_outs_with_preprocessing)\n",
    "overlap = 50\n",
    "max_chunk_size = 2000\n",
    "def chunker(text, overlap=50, max_chunk_size=2000, add_overlap=True):\n",
    "\n",
    "    chunks = []\n",
    "\n",
    "    current_chunk = []\n",
    "\n",
    "    chunk_size = 0\n",
    "\n",
    "    paragraphs = re.split(\"\\n\\s*\\n\", text)\n",
    "    for paragraph in paragraphs:\n",
    "        para_length = len(paragraph)\n",
    "\n",
    "        if chunk_size + para_length <= max_chunk_size:\n",
    "            current_chunk.append(paragraph)\n",
    "            chunk_size += para_length\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(\"\\n\\n\".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            chunk_size = 0\n",
    "\n",
    "            lines = paragraph.split(\"\\n\")\n",
    "            num_of_lines_not_taken = len(lines)\n",
    "\n",
    "            while num_of_lines_not_taken > 0:\n",
    "\n",
    "                num_lines_to_take = min(int(float(max_chunk_size / para_length) * len(lines)), num_of_lines_not_taken)\n",
    "\n",
    "                lines_to_add = lines[:num_lines_to_take]\n",
    "                joined_lines = \"\\n\".join(lines_to_add)\n",
    "\n",
    "                while len(joined_lines) > max_chunk_size and num_lines_to_take > 1:\n",
    "                    num_lines_to_take -= 1\n",
    "                    lines_to_add = lines[:num_lines_to_take]\n",
    "                    joined_lines = \"\\n\".join(lines_to_add)\n",
    "\n",
    "\n",
    "                if len(joined_lines) <= max_chunk_size:\n",
    "                    current_chunk.append(joined_lines)\n",
    "                    chunk_size += len(joined_lines)\n",
    "                \n",
    "                if current_chunk:\n",
    "                    chunks.append(\"\\n\\n\".join(current_chunk))\n",
    "                current_chunk = []\n",
    "                chunk_size = 0\n",
    "                num_of_lines_not_taken -= num_lines_to_take        \n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\"\\n\\n\".join(current_chunk) if len(current_chunk) > 1 else current_chunk[0])\n",
    "\n",
    "    \n",
    "# time to add overlap between chunks\n",
    "    if not add_overlap:\n",
    "        return chunks\n",
    "    \n",
    "    \n",
    "    for i in range(1, len(chunks)):\n",
    "        chunks[i] = \" \".join(chunks[i-1].split()[-overlap:]) + \" \" + chunks[i]\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64639c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunker(text, overlap=overlap, max_chunk_size=max_chunk_size, add_overlap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d90ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c155868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "OCR_CLEANING_SYSTEM_PROMPT = (\n",
    "    \"You are an expert in cleaning OCR induced errors in the text. \\n\"\n",
    "    \"Follow the instructions below to clean the text, ensuring the text flows coherently with the previous context:\\n\"\n",
    "    \"1. Fix OCR induced typographical errors, such as incorrect characters or spacing.\\n\"\n",
    "    \"- Use provided context and common sense to identify and correct errors.\\n\"\n",
    "    \"- For example, 'l' and '1' or 'o' and '0' are often confused.\\n\"\n",
    "    \"- Ensure that the text is grammatically correct and coherent.\\n\"\n",
    "    \"- Remove any unnecessary line breaks or extra spaces.\\n\"\n",
    "    \"- Identify and correct word splits and line breaks.\\n\"\n",
    "    \"- Only fix clear OCR errors. DO NOT ALTER THE CONTEXT OR MEANING of the text.\\n\"\n",
    "    \"- DO NOT add any generated text, punctuation, or capitalization.\\n\"\n",
    "    \"2. Ensure structure is maintained.\\n\"\n",
    "    \"- Maintain original structure, including paragraphs and line breaks.\\n\"\n",
    "    \"- Preserve the original content. \\n\"\n",
    "    \"- Keep all importatnt information intact.\\n\"\n",
    "    \"- DO NOT add any new text not present in the text. \\n\"\n",
    "    \"3. Ensure flow and coherence.\\n\"\n",
    "    \"- Ensure the text flows naturally and coherently.\\n\"\n",
    "    \"- Use provided context to ensure the text makes sense.\\n\"\n",
    "    \"- HANDLE text that starts or ends mid-sentence correctly. \\n\\n\"\n",
    "    \"4. Return ONLY the cleaned text.\\n\"\n",
    "    \"- Do not add any additional information, explanations, or thoughts.\\n\"\n",
    "    \"- Do not include your thoughts, explanations, or steps.\\n\"\n",
    "    \"- Do not add any new text not present in the text.\\n\"\n",
    ")\n",
    "OCR_CLEANING_PROMPT = lambda context, text: (\n",
    "    # \"IMPORTATANT: RETURN ONLY THE CLEANED TEXT. Preserve the orignial structure and content. Do not add anything else. Do not include your thoughts, explantions or steps.\\n\\n\"\n",
    "    f\"Previous context:\\n {context}\\n\\n\"\n",
    "    f\"Text to clean:\\n {text}\\n\\n\"\n",
    "    \"Cleaned text:\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fa9ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.bfloat16, device_map=\"auto\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633c8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ocr_clean(system_message, message, model, tokenizer):\n",
    "    \n",
    "    conversation = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": message}]\n",
    "\n",
    "    # format and tokenize the tool use prompt \n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "                conversation,\n",
    "                return_dict=True,\n",
    "                return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    print(\"Inputs generated\")\n",
    "    print(\"Input size:\", inputs.input_ids.shape)\n",
    "    max_tokens = inputs.input_ids.shape[1]\n",
    "    print(\"Max tokens:\", max_tokens)\n",
    "    \n",
    "\n",
    "    inputs.to(model.device)\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=max_tokens)\n",
    "    print(\"Outputs generated\")\n",
    "    generated_ids = [\n",
    "                output_ids[len(input_ids) :]\n",
    "                for input_ids, output_ids in zip(inputs.input_ids, outputs)\n",
    "            ]\n",
    "    final_out = tokenizer.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    print(\"Final Output Generated\")\n",
    "    #print(final_out[0])\n",
    "    \n",
    "    return final_out[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d2e76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "outs = []\n",
    "context = \"\"\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(\"========================================================================\")\n",
    "    print(f\"Chunk {i+1}/{len(chunks)}\")\n",
    "    message = OCR_CLEANING_PROMPT(context, chunk)\n",
    "    print(\"Message generated\")\n",
    "    out = ocr_clean(OCR_CLEANING_SYSTEM_PROMPT, message, model, tokenizer)\n",
    "    print(\"Output generated\")\n",
    "    outs.append(out)\n",
    "    context = out[-500:] if len(out) > 500 else out\n",
    "    print(\"========================================================================\")\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c423a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7e41cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def extract_tokens_and_spans(text: str) -> tuple[list[str], list[tuple[int, int]]]:\n",
    "    \"\"\"\n",
    "    Extracts tokens and their character spans from a given text.\n",
    "    This function identifies non-whitespace runs in the text, strips leading and trailing punctuation,\n",
    "    and returns a list of tokens along with their character spans in the original text.\n",
    "    It uses regular expressions to find non-whitespace sequences and captures their start and end positions.\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text from which to extract tokens and spans.\n",
    "\n",
    "    Returns:\n",
    "        tuple[list[str], list[tuple[int, int]]]: A tuple containing: clean tokens (list of str) and their corresponding spans (list of tuples).\n",
    "    \"\"\"\n",
    "    tokens, spans = [], []\n",
    "    for match in re.finditer(r'\\S+', text):                # find non-whitespace runs\n",
    "        tok = match.group()\n",
    "        clean = tok.strip(string.punctuation)          # strip leading/trailing punctuation\n",
    "        if clean:\n",
    "            tokens.append(clean)\n",
    "            spans.append(match.span())                     # (start_char, end_char) of the original tok\n",
    "    return tokens, spans\n",
    "\n",
    "\n",
    "def merge_chunks_fuzzy(chunk_a, chunk_b,\n",
    "                       overlap_words=50,\n",
    "                       window_size=10,\n",
    "                       threshold=90):\n",
    "    \"\"\"\n",
    "    Fuzzy-merge two text chunks by detecting an overlap of up to `overlap_words`\n",
    "    (scanning `chunk_b` in a sliding window of that many cleaned tokens + a little buffer),\n",
    "    but splice them together on the ORIGINAL strings so all whitespace/newlines/punctuation\n",
    "    outside the matched overlap are preserved.\n",
    "    \"\"\"\n",
    "\n",
    "    tokens_a, _ = extract_tokens_and_spans(chunk_a)\n",
    "    tokens_b, spans_b = extract_tokens_and_spans(chunk_b)\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Iteratively\n",
    "\n",
    "    Left chunk: tokens_a <- Start from double the overlap words to create a tail\n",
    "    Right chunk: tokens_b <- Start from doubles the overlap words to create a head\n",
    "\n",
    "    Find the ratio, and best index / ratio\n",
    "\n",
    "    until index is 0 -> regenerate the tail and head with the new index such that the new tail is tail[new_idx:] and head is head[:new_idx + 1]\n",
    "    If the best ratio is above the threshold, splice the two chunks together at the best index.\n",
    "    If the best ratio is below the threshold, concatenate the two chunks.\n",
    "    If the best index is 0, just concatenate the two chunks.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    window = int((overlap_words * 1.2) + window_size)\n",
    "    best_ratio, best_i = 0, 0\n",
    "    while window > 0:\n",
    "        tail = \" \".join(tokens_a[-window:])\n",
    "        head = \" \".join(tokens_b[:window + 1])\n",
    "\n",
    "        ratio = fuzz.partial_ratio(tail, head)\n",
    "\n",
    "        if ratio > best_ratio:\n",
    "            best_ratio = ratio\n",
    "            best_i = window\n",
    "        \n",
    "        window -= 1\n",
    "    # if we found a good overlap → compute the character-offset in chunk_b\n",
    "\n",
    "    if best_ratio >= threshold:\n",
    "        cut_pos = spans_b[best_i][0] if best_i < len(spans_b) else len(chunk_b)\n",
    "        # splice: keep all of chunk_a, then everything in chunk_b from that char-offset onward\n",
    "        return chunk_a + \"\\n\\n\" + chunk_b[cut_pos:]\n",
    "    else:\n",
    "        # no confident overlap → just concatenate in full\n",
    "        return chunk_a + \"\\n\\n\" + chunk_b\n",
    "\n",
    "\n",
    "def merge_sentences(sents, overlap_words=50, window_size=10, threshold=90):\n",
    "\n",
    "    assert len(sents) > 0, \"No sentences to merge\"\n",
    "\n",
    "\n",
    "    if len(sents) == 1:\n",
    "        return sents[0]\n",
    "\n",
    "    merge_to = sents[0]\n",
    "\n",
    "    for i in range(1, len(sents)):\n",
    "        merge_to = merge_chunks_fuzzy(merge_to, sents[i], overlap_words=50, window_size=10, threshold=90)\n",
    "    return merge_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009462fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Hello\"[0:]\n",
    "\"Hello\"[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85aa3071",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge = merge_sentences(outs, overlap_words=overlap, window_size=10, threshold=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627899b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c19f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.data_processing.text_processing import TextProcessor\n",
    "divisions = [\"Dicotyledones\", \"Monocotyledones\", \"Pteridophyta\", \"Hepaticae\", \"Algae\"]\n",
    "text_processor = TextProcessor()\n",
    "#text_blocks = text_processor.make_text_blocks(text_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f4f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_text = text_processor.preprocess_text(final_merge, divisions[0])\n",
    "print(c_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec50fee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "div_split = text_processor.split_by_divisions(c_text, divisions)\n",
    "print(div_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e1c6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = div_split[\"Dicotyledones\"]\n",
    "\n",
    "finds = re.finditer(text_processor.family_regex, sample)\n",
    "\n",
    "find_matches = [i for i in finds]\n",
    "text_chunks = []\n",
    "\n",
    "for idx, i in enumerate(find_matches):\n",
    "    match = re.sub(r\"[.\\n\\t,]*\\s*([A-Z]+)\\s*[.\\n\\t,]*\", r\"\\1\", i.group())\n",
    "    start = i.end()\n",
    "    end = find_matches[idx+1].start() if idx+1 < len(find_matches) else None\n",
    "    text_chunk = sample[start:end] if end else sample[start:]\n",
    "    text_chunks.append(dict(family=match, text=text_chunk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4320c23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb12337",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in text_chunks:\n",
    "    print(\"Family: {0} ==> {1}\".format(i[\"family\"], len(i[\"text\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e53a7e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854ce1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"=\"*50)  # Separator for readability\n",
    "\n",
    "# family_chunk_overlap = 100\n",
    "# family_chunk_size = 2000\n",
    "# for i in range(len(text_chunks)):\n",
    "\n",
    "#     if len(text_chunks[i]['text']) < max_chunk_size:\n",
    "#         text_chunks[i]['chunks'] = [text_chunks[i]['text']]\n",
    "#         print(\"Chunk is smaller than max_chunk_size, skipping chunking.\")\n",
    "#         print(\"=\"*50)\n",
    "#         continue\n",
    "    \n",
    "#     print(\"Found chunk larger than max_chunk_size: {0} characters\".format(len(text_chunks[i]['text'])))\n",
    "#     print(f\"Family: {text_chunks[i]['family']}\")\n",
    "#     print(f\"Text: {text_chunks[i]['text'][:100]}...\")  # Print first 100 characters\n",
    "#     print(\"=\"*50)  # Separator for readability\n",
    "\n",
    "#     new_chunks = chunker(text_chunks[i]['text'], overlap=family_chunk_overlap, max_chunk_size=family_chunk_size, add_overlap=False)\n",
    "\n",
    "#     text_chunks[i]['chunks'] = new_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a09cd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a514868b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MARKDOWN_SYSTEM_PROMPT = (\n",
    "# #     \"You are an expert in converting text to markdown format. \\n\"\n",
    "# #     \"Follow the instructions below to convert the text to markdown format:\\n\"\n",
    "# #     \"1. Convert the text to markdown format.\\n\"\n",
    "# #     \"- Preserve original content, heading. Add a blank line before and after each heading.\\n\"\n",
    "# #     \"- If headers are capitalised, keep them capitalised.\\n\"\n",
    "# #     \"- Use appropriate markdown syntax for headings, lists, and other elements.\\n\"\n",
    "# #     \"- Ensure that the text is properly formatted and easy to read.\\n\"\n",
    "# #     \"- Use appropriate markdown syntax for links, images, and other elements.\\n\"\n",
    "# #     \"2. Remove any content that may have been added by the LLM and was not present in the original text.\\n\"\n",
    "# #     \"- Remove any unnecessary line breaks or extra spaces.\\n\"\n",
    "# #     \"- Identify and correct word splits and line breaks.\\n\"\n",
    "# #     \"3. Preserve all original content. \\n\"\n",
    "# #     \"4. Ensure structure is maintained.\\n\"\n",
    "# #     \"- Maintain original structure, including paragraphs and line breaks.\\n\"\n",
    "# #     \"- Preserve the original content. \\n\"\n",
    "# #     \"- Keep all important information intact.\\n\"\n",
    "# #     \"- DO NOT add any new text not present in the text. \\n\\n\"\n",
    "# #     )\n",
    "\n",
    "# MARKDOWN_SYSTEM_PROMPT = (\n",
    "#     \"You are an expert in converting text to JSON Lines.\\n\"\n",
    "#     \"I have a botanical catalogue where each record starts with a species name line, then a number of folders, then items.\\n\"\n",
    "#     \"Please parse the following into a JSON Lines (NDJSON) stream. Each object should have:\\n\"\n",
    "#     \"- `species`: the species name (the first line of the record)\\n\"\n",
    "#     \"- `folders`: a list of folder names (the lines after the species name and before the items)\\n\"\n",
    "#     \"Ensure the following instructions are followed:\\n\"\n",
    "#     \"1. Parse into JSON Lines.\\n\"\n",
    "#     \"- Ensure each record is a valid JSON object.\\n\"\n",
    "#     \"- Each record should have the keys `species` and `folders`.\\n\"\n",
    "#     \"- The `species` key should contain the species name.\\n\"\n",
    "#     \"- The `folders` key should lines of text under the species.\\n\"\n",
    "#     \"- Do not add any new text not present in the text.\\n\"\n",
    "#     \"- Collect the lines of text under the species name as a list of strings and store in `folders`.\\n\"\n",
    "#     \"- Use common sesne and provided context to ensure the text makes sense.\\n\\n\"\n",
    "#     \"2. Ensure flow and coherence.\\n\"\n",
    "#     \"- Ensure the text flows naturally and coherently.\\n\"\n",
    "#     \"- Use provided context to ensure the text makes sense.\\n\"\n",
    "#     \"- HANDLE text that starts or ends mid-sentence correctly. \\n\\n\"\n",
    "#     \"3. Preserve all original content. \\n\"\n",
    "#     \"- Preserve original content, headings, and structure.\\n\"\n",
    "#     \"- Do not add any new text not present in the text.\\n\"\n",
    "#     \"- Keep all important information intact.\\n\"\n",
    "#     \"- DO NOT add any new text not present in the text. \\n\\n\"\n",
    "#     \"4. ONLY return the JSON Lines output.\\n\"\n",
    "#     \"- Do not add any additional information, explanations, or thoughts.\\n\"\n",
    "#     \"- Do not include your thoughts, explanations, or steps.\\n\"\n",
    "#     \"- Do not add any new text not present in the text.\\n\"\n",
    "#     )\n",
    "\n",
    "# MARKDOWN_PROMPT = lambda text: (\n",
    "#     f\"Parse into JSON lines:\\n {text}\\n\\n\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902e91cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, chunk in enumerate(text_chunks):\n",
    "#     print(\"========================================================================\")\n",
    "#     print(f\"Processing chunk for family: {chunk['family']}\")\n",
    "\n",
    "#     for j, sub_chunk in enumerate(chunk['chunks']):\n",
    "#         print(f\"Processing chunk {j+1}/{len(chunk['chunks'])}\")\n",
    "#         message = MARKDOWN_PROMPT(sub_chunk)\n",
    "#         print(\"Message generated\")\n",
    "#         out = ocr_clean(MARKDOWN_SYSTEM_PROMPT, message, model, tokenizer)\n",
    "#         print(\"Output generated\")\n",
    "\n",
    "#         if 'chunks_cleaned' not in text_chunks[i]:\n",
    "#             text_chunks[i]['chunks_cleaned'] = []\n",
    "#         text_chunks[i]['chunks_cleaned'].append(out)\n",
    "#     print(\"========================================================================\")\n",
    "#     gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2520e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cae6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bde42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.0/en_core_eco_md-1.0.2.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74f5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from taxonerd import TaxoNERD\n",
    "\n",
    "class SpeciesChunker:\n",
    "\n",
    "    SPECIES_REGEX = r\"([A-Z][a-z]+(?: [a-z]+)\\s?(?:[a-zA-Z\\[\\]\\(\\)\\.\\s\\,]+)?)\"\n",
    "\n",
    "    def __init__(self, threshold=90):\n",
    "\n",
    "        self.threshold = threshold\n",
    "        self.nlp = None\n",
    "        \n",
    "    def load(self):\n",
    "        if self.nlp is not None:\n",
    "            raise RuntimeError(\"Chunker is already loaded. Please create a new instance to load again.\")\n",
    "        \n",
    "        taxonerd = TaxoNERD(prefer_gpu=False)\n",
    "        self.nlp = taxonerd.load(\"en_core_eco_md\", exclude=[], threshold=self.threshold)\n",
    "\n",
    "    def chunk_species(self, text: str) -> list[str]:\n",
    "        \"\"\"\n",
    "        Chunk the text into species records using TaxoNERD.\n",
    "        Returns a list of dictionaries with species and folders.\n",
    "        \"\"\"\n",
    "        if self.nlp is None:\n",
    "            print(\"Chunker is not loaded. Loading Chunker...\")\n",
    "            self.load()\n",
    "\n",
    "        doc = self.nlp(text)\n",
    "        species_names = doc.ents\n",
    "\n",
    "        all_valid_species = \"|\".join(re.escape(i.text) for i in species_names if re.match(self.SPECIES_REGEX, i.text))\n",
    "\n",
    "        split_regex = re.compile(rf\"^(([0-9]+\\.\\s?)?(\\s+|-)?({all_valid_species})\\s*.*)\")\n",
    "\n",
    "        text_splits = text.split(\"\\n\")\n",
    "\n",
    "        chunks = []\n",
    "\n",
    "        current_chunk = \"\"\n",
    "\n",
    "        for line in text_splits:\n",
    "            if not(line.strip()):\n",
    "                print(\"Skipping empty line\")\n",
    "                continue\n",
    "            if re.match(split_regex, line):\n",
    "                print(current_chunk)\n",
    "                if current_chunk:\n",
    "                    chunks.append(current_chunk.strip())\n",
    "                    print(\"Chunk added:\\n\", current_chunk.strip())\n",
    "                    print(\"=\" * 50)\n",
    "\n",
    "                current_chunk = line.strip()\n",
    "                print(\"Matched:\", line)\n",
    "                print(current_chunk)\n",
    "            else:\n",
    "                current_chunk += \"\\n\" + line.strip()\n",
    "                print(\"Not matched:\", line)\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def group_into_major_chunks(self, chunks: list[str], max_chunk_size: int = 2000) -> list[str]:\n",
    "\n",
    "        major_chunks = []\n",
    "        current_chunk = \"\"\n",
    "\n",
    "        for chunk in chunks:\n",
    "            if len(current_chunk) + len(chunk) > max_chunk_size:\n",
    "                major_chunks.append(current_chunk.strip())\n",
    "                current_chunk = chunk.strip()\n",
    "            else:\n",
    "                current_chunk += \"\\n\\n\" + chunk.strip()\n",
    "        \n",
    "        if current_chunk:\n",
    "            major_chunks.append(current_chunk.strip())\n",
    "\n",
    "        return major_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f594a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunker = SpeciesChunker(threshold=70)\n",
    "\n",
    "chunker.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1f9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, text_chunk in enumerate(text_chunks):\n",
    "\n",
    "    chunks = chunker.chunk_species(text_chunk[\"text\"])\n",
    "    text_chunks[i][\"species_chunks\"] = chunker.group_into_major_chunks(chunks, max_chunk_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e900300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415e1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8648b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_eco_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7377d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"\"\"\n",
    "Dicotyledones\n",
    "ACERACRAE\n",
    "Acer campestre L.\n",
    "1 folder. Acer campestre [TA]\n",
    "Acer pseudoplatanus L.\n",
    "2 folders. ot\n",
    "Folder 1. Acer Pseudo-Platanus\n",
    "[G]. i. “Maple. Bulls: [Bulstrode]\n",
    "\n",
    "Park” [JL]\n",
    "Folder 2. Acer Pseudo-Platanus\n",
    "[TA].\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f559139",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f62dd566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.get_lca_matrix().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aa0098d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dicotyledones'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9a0672",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lcat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
